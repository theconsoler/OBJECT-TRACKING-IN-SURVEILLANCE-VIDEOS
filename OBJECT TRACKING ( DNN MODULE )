import cv2
import math
import os

# Load video file
video_path = "C:/Users/ASUS/Downloads/jupyter projects/Car Road Transportation.mp4"
cap = cv2.VideoCapture(video_path)

# Check if the video opened successfully
if not cap.isOpened():
    print("Error: Couldn't open video file.")
    exit()

# Get video properties for saving
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Create the output directory if it doesn't exist
output_dir = "output"
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Define the codec and create VideoWriter object
output_video = cv2.VideoWriter(
    os.path.join(output_dir, "processed_video.avi"), cv2.VideoWriter_fourcc(*"XVID"), fps, (frame_width, frame_height)
)

# Check if VideoWriter was successfully initialized
if not output_video.isOpened():
    print("Error: Couldn't open the video writer.")
    exit()

# Initialize variables
count = 0
center_points_prev_frame = []
tracking_objects = {}
track_id = 0

# Create a background subtractor (using MOG2 in this case)
fgbg = cv2.createBackgroundSubtractorMOG2()

# Initialize the minimum bounding box size for car detection (tune this based on your use case)
min_car_area = 500  # Minimum area of bounding box to track (adjust as necessary)
max_car_area = 5000  # Maximum area of bounding box (adjust as necessary)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Apply background subtraction
    fg_mask = fgbg.apply(frame)

    # Find contours in the mask (i.e., detected moving objects)
    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    center_points_cur_frame = []

    for contour in contours:
        # Filter out small or too large contours (noise and irrelevant objects)
        if cv2.contourArea(contour) < min_car_area or cv2.contourArea(contour) > max_car_area:
            continue

        # Get the bounding box around each contour
        (x, y, w, h) = cv2.boundingRect(contour)

        # Calculate the center points of the bounding box
        cx = int((x + x + w) / 2)
        cy = int((y + y + h) / 2)
        center_points_cur_frame.append((cx, cy))

        # Draw rectangle around the object
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Update tracking objects only if cars are detected consistently
    for pt in center_points_cur_frame:
        same_object_detected = False
        for object_id, prev_pt in tracking_objects.items():
            distance = math.hypot(prev_pt[0] - pt[0], prev_pt[1] - pt[1])

            # Only update if the object is sufficiently close (distance threshold)
            if distance < 50:  # Threshold distance for matching objects (adjust as needed)
                tracking_objects[object_id] = pt
                same_object_detected = True
                break

        # Assign a new ID to a new object (if no match found)
        if not same_object_detected:
            tracking_objects[track_id] = pt
            track_id += 1

    # Draw tracking points and IDs
    for object_id, pt in tracking_objects.items():
        # Draw a filled circle for tracking
        cv2.circle(frame, pt, 5, (0, 0, 255), -1)

        # Ensure IDs are drawn on top of the frame
        cv2.putText(
            frame,
            str(object_id),
            (pt[0] - 10, pt[1] - 10),  # Offset for better visibility
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (255, 255, 255),  # White text for visibility
            2,
            lineType=cv2.LINE_AA,  # Anti-aliased text
        )

    # Write the processed frame to the output video
    output_video.write(frame)

    # Optionally, display the frame (debugging or if you want to watch the video while processing)
    # cv2.imshow("Frame", frame)

    # Exit if the user presses 'q' (optional)
    # if cv2.waitKey(1) & 0xFF == ord('q'):
    #     break

# Release everything when done
cap.release()
output_video.release()

# Optionally, close all OpenCV windows (if cv2.imshow is used)
# cv2.destroyAllWindows()

print("Processing complete. The output video is saved in the 'output' directory.")
